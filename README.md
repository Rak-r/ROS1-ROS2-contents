# ROS1-Ros2-contents
This repoistroy contains the information about the concepts of ROS1 and ROS2
#######################################ROS1-ROS2 PORTING################################################################:

Podacr package structure:
Podcar
..>>>>launch
	.>all launch files of the podcar (slam, nav2, controls, worlds)
..>>>>mdoels
	..all models (of podcar, world, lincolnINB, LeedsUni)
..>>>>config
	..contains all the configurations/params in yaml format.
......scripts
	..all scripts for controlling(joystick, arduino etc).
......msg
	..contains the msg files in .msg extension.
......If package is of python build type then it will have setup.py, setup.config, resources directry as well while if the packge build type is CMake then it will have Package.xml, CMakeLists.txt

Work:

1.) Started with the podcar package pf ROS1  and made chnages to the launch files present.

Major attention required: The launch files maybe of xml or python format but in ros2 there has been some changes in the name of arguements and attributes like type>exec, ns>namespace. Also the Navigation stack has been upgraded wuth some more functionalities and there has been chnages in the terms and packages. Howeverthe basic concept is the same as ROS1.

PACKAGES WHICH HAS BEEN CHANGED ARE:

1.)The Gmapping package for the mapping task in ROS1 with other skam packages like Karto, cartographer and the building slam_toolbox which steve mckenzie has introduced in ROS2, it basically offers structured functionality. Some parameters have been renamed but does the same task.

2.)The Adaptive Monte Carlo Localization package of the nav_stack has te same adopted to nav2.

3.)map_server apckage has been renamed to nav2_map_server: This package implements a server to handle the request of the map loading and also gives a map topic (map_server/map). There is also a map saver server running in the backend which saves the generated map according to the service requests.

4.) nav2_plannar replaces the global planner in ROS2 and nav2_controller replaced the local planner.

5.) What is planner, controller, behaviour and smoother servers?

Planners: Planner serveer are used to compute the global plan or the shortest path.

Controllers: These servers are used to follow he the global plan generated by the planner. These were called a slocal planners in ROS1.

Behaviors: For instance, suppose the robot has been stuck at some point due to some obstackle coming in ts way. The behaviour servers makes it possible for the robit to act in thses king=d of scenarios through the actions like turning back, spinning which brings the robot into obstcakle free zone.

Smoothers: Sometimes we cannot fully rely on the path provided/computed by the plnner so we use the smoother server swhich helps in refining the planer path.

6.) Waypoint_Follower: Navigation 2 features a nav2_waypoint_follower which has a plugin interface and helps to complete a specific task/operation for example; bringing the cup etc.

STATE ETIMATION: THIS TASK IS DONE IN TWO STAGES:  

map>odom frame transformation isdone using different methods (SLAM, localization, mapping) and odom>base_frame is done using various odometry systems such as Wheel encoders, visual cameras, IMUS and fusion of these.

Costmaps: Costmaps are the 2D occupancy grid maps which represents the environment for the robot. In these grids, the cell stores the value between (0-254) and the one with the value 0 means = No Occupancy while cell with value 254 = Lethally Occupied.
Costmaps have different layers which consist different information about the environment.

1.) Static layer: Represents the map section of the costmap.

2.) Obstacle layer: Represents the objects detected by the sensors that publishes either or both LaserScan and PointCloud messages.

3.) Voxel layer: Does the same thing as that of the obstacle layer but handles the 3D data.

4.) Inflation layer: Represents the added cost values around the obstacles.


Joint state Publisher: In order to move the robot for a specific task or operation it is important to have the full detailed data of veery joint of the robot like the angle for the moving joint, displacemnet of linear actuator and velocity. Joint state publisher is used to keeping the track of this data and sends it to Robot state Publisher.

Robot state Publisher: This recieves the data from the Joint state publisher and outputs the position and orientation of each coordinate frame and this data is pubishes to the TF2 library/package of ROS2 which keeps the track record for all the co-ordinate frames over time.

TF2 library: It takes the input from the robot state publsher and is responsilble for keeping track of pose estimate and orientation of all coordinate frames over time.

Fusion of sensors: The data recieved or collected from different sensors like LiDARs, Caneras, IMUs etc need to fused in order to use that infomation for robust working in different scenarios. To fuse the multi-sensor data, mtoion models are used and one of the most common method used is called Kalman Filtering. The Different-drive robot, Ackermann steered robot mostly uses Extended Kalman filtering (EKF) and partu=icle filter Monte Carlo method is used.


SLAM ToolBox: (https://github.com/SteveMacenski/slam_toolbox)

ROS1 featured different SLAM approaches in order to build the map and perform localization. These methods are Gmapping, Cartograph, Karto Slam. In ROS2, the Gmapping has been replaced with Slam_toolbox.
Slam_toolbox works in the following way:

1.) ROS Node: SLAM toolbox runs in synchronous mode and generates a ros node hwich subcribes tpo the laser scan and odometry topics and publishes map to odom transform and a map.

2.) Getting LiDAR and Odometry Data: A callback from laser topic generates a pose and a laser scan is attached to the node. The posedscan objects makes a queue, which uis processed by the algorithm (Karto).

3.) Pose Graph: The PosedScan object queue are used to form a pose graph which is utilised compute the robot pose and find loop closures.

4.) Mapping: Laser scans associated to each pose in the Pose Graph are used to construct and publish a map.

Loop Closure: Ability of a SLAM algorithm to identify the previously detected images and correct the drift accumulated during the sensor movement.

The basic idea behind the Slam_toolbox or Gmapping in ROS1 is that we can create a map of the environment which can then be saved and used for navigation of the robot. 
How to run the slam_toolbox in ROS2.
Firstly, look at the congfiguartion file in the official slam-toolbox repository to get some idea of the terms. 
Then just create the parameters/config in your robot workspace/src/robot_slam package. 
Initially, copy the configs values for testing. Then create a launch file which can used from the reference from the repository only. 
BUild the package. <colcon build --symlink-install>
<source install/setup.bash> (Don't forget to source the overlay i.e. source /opt/ros/ros-distro/setp.bash).
Use the <ros2 launch> command to launch the slam_toolbox and view in rviz.
  
Navigation 2(https://github.com/ros-planning/navigation2)

Planner are used to compute the shortest path in the enviroment for the robot using the algorithms.

Different algorithms used:

1.) NavFn: This algorithm uses either Dijkstra or A*.
2.) Smac 2D planner: This implemnts a 2D A* algorithm using 4 or 8 connected neighbourhood with a smoother query.

Issue with these planners is that they may not be feasable to provide the map for the robot whch is Ackermann steered and legged robots.

3.) SMAC Hybrid A* Planner: This algorithm provides the support for Ackermann and legged robots and supports the Dubin and Reeds-Shepp motion nmodels.

Controller Server: These are used to follow the path computed by the planner server and also to perform other task such as avoiding obstacles.

Different Algorithms used:

1.) DWB controller based on Dynamic window approach algorithm which have configurable plugins to compute the commands for the robots.

2.) Other controller server plugin is the TEB (Time Elastic Band) which optimizes the robot's trajectory based on its execution time, distance form obstacle and feasability w.r.t robot's kinematic constraints. Can be used fo Ackermann , legged robots.

Major changes:

rospy --> rclpy

URDF/SDF

Coming to the structure for building the urdf file for the robot, xacro software can be used if the model is too complex. Things to keep in mind when dealing with URDF files.
Below are the list of common things to consider while developing the URDF.
URDF files are used to describe the robot in the ros environment and SDF files are used to describe the robot in Gazebo simulation.

Link labels have three main tags:

1.) Visual: DEscribes the robot visual properties (how it will look).
2.) Collision: Physical properties that govern the robot collision with other objects.
3.) Inertial: Describes some physics properties of the robot. (mass, inertia along axis, origin etc).

Joint tags/labels: These are used to create the joint between two links. Includes name tag, type: Revolute for wheelss, continous etc, parent and child link names.

Errors in building URDF for robots:
1.) Check the xml parsings and tags, correct spacing and tag closings.
2.) In the urdf file define the base_footprint for ease and a joint fixing base-footprint with base_link/chassiss in case of car/4WD robots. carefully define the link lables with providing the origin tag, collision tag, visual tag.
3.) Joint labels should be defined to show the connection between two links (parent and child).
4.) Failed to find the root link: 2 root links found.

SOLUTION: Set a parent link to one of those two links according to your robot structure.

5.) Rviz2 not showing the mesh file and dae.file for your robot model.

Solution: Make sure you added the meshes or the directory of your STL and .dae files to the CmakeLists.txt of the package which you are running.

Secondly, try to use file://$(find package_name) instead of file://package in the mesh file path in your urdf.
Thirdly, try to replace the path with the absolute path of the stl/dae files.

Note: Rviz2 axis colour and designation: x- Red, y-Green z-Blue.

If Robot model appears in the rviz2 console and the joints are cluttered, then try to manipulate with the origin xyz and rpy values of those particular joints one by one and visualize the changes by launch file again and again.
6.) To check the URDF is correctly built, try the command in the terminal : check_urdf <name of the urdf file>
  
Gazebo converts the URDF to SDF format itself when passed through the launch files. Also, if using xacro, then it automatically parses the complete URDF to gazebo.(Later in this repo). There are lot of errors occur in Gazebo when using launch files to view the ROS URDF model in gazebo. 
I tried to mention the one I faced with some solutions below:
1.) Warning: Non-unique names in gazebo simulation. Solution: Can ignore the warning or just use different names for each link and joint.
2.) Cannot have 2 joints with same name.
Meaning? A child link can have only one parent but a parent link can have as many child links. 
Solution: Check in the irdf or sdf if a child link is having two/more parent link and correct it.

3.) LoadJoint failed: Correcting the above error will automatically resolve this one.
4,) In ROS2, Joint State Publisher in gazebo plugin is used as <joint_name> enter_the_name_of_the_joint</joint_name>.
5.) Gazebo server already in use: 
Try--> killall gazebo OR killall gzserver and restart terminal OR sudo pkill -9 gzserver. Use ps for more help.
  
After successfully building the urdf and viewing it in RViz and Gazebo, now to control the robot there are different ways.
First method to move the robot in simulation is to use gazebo plugins which are already made available to users from gazebo. (Diff. drive, Tricycle Drive and others can be found at: https://github.com/ros-simulation/gazebo_ros_pkgs).
Second method is newly introduced in ROS2, the ros2_control package. This involves a hardware interface,a controller manager and controller interface. The controller manager acts as a communication medium between the hardware interface and controller interface.
Third, there are some diffrent robots with different kinematics models namely, Ackermann steered robot in our case and there is no support of gazebo plugin for this right now. There are some sources which uses ackermann steer robots, hiwver these rae based on ROS1. Therefore, to handle this issue we are struggling to find different ways to implement and acheive this. 
1.) As per the design of the podcar consider a trcaking rod connected to base link in the front to which the right and left pivots are connected and to the pivots the front right and front left wheels are connected.
2.) Plan is to  apply force to the rod so that it can move in either right/left.

How?

Ackermann demands the velocity message in x for logitudenal movemnet (front or reverse) and angular velocity in z (y) for steering angle movement.
So writing samll ros2 nodes can help with this. start with joystick package of ros2 and take the commands of the joystick node which outs the topic with message type /Joy.
Convert this /Joy message to speed command  (x) and angular command for wheel steer (z) using ros2 nodes joy2speed.py and joy2wheelangle.py.
After that, provide these converted messages to anothers nodes cmd_velhandler to get the main messages which are: joy2speed to /speedcmd_vel and joy2wheel to /wheelAnglecmd.

Then, a simple ros_gazebo plugin can be cretaed which will not do any calculations but just transfer the ros2 messages came form the small nodes to gazebo for simualtion and controlling. 



  


